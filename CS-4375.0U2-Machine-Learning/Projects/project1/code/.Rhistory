if(!require==MASS){
library(MASS)
}
if(!require==MASS){
library(MASS)
}
if(!require==mass){
library(mass)
}
if(!require=mass){
if(!require==mass){
library(mass)
}
if(!require(mass){
if(!require('MASS'){
if(!require('MASS')){
library(mass)
}
if(!require('MASS')){
library('MASS')
}
plot(women$weight~women$height)
albine(lm(women$weight$height), col="red")
abline(lm(women$weight$height), col="red")
abline(lm(women$weight~women$height), col="red")
lm1 <- lm(weight~height, data=women)
lm1
lm1 <- lm(weight~height, data=women)
lm1
summary(lm1)
corr(weight,height)
cor(weight,height)
cov(weight,height)
lm(formula = weight ~ height, data = women)
cor(weight,height)
lm1 <- lm(weight~height, data=women)
lm1
data(women)
str(women)
plot(women$weight~women$height)
abline(lm(women$weight~women$height), col="red")
lm1 <- lm(weight~height, data=women)
lm1
summary(lm1)
cov(weight,height)
test <- women[c(5, 9, 11),]
test[1, 2] <- 135
test[2, 2] <- 118
test[3, 2] <- 156
test
pred <- predict(lm1, newdata=test)
pred <- predict(lm1, newdata=test)
data
data
data()
?swiss
#
str(swiss)
#
head(swiss)
#
plot(swiss$Fertility~swiss$Education)
lml <- lm(Fertility~Education, data=swiss)
summary(lml)
str(swiss)
#
head(swiss)
attach(swiss)
#
plot(swiss$Fertility~swiss$Education)
lml <- lm(Fertility~Education, data=swiss)
summary(lml)
cov(swiss$Fertility,swiss$Education)
cor(swiss$Fertility,swiss$Education)
lm2 <- lm(Fertility~., data=swiss)
summary(lm2)
lm2 <- lm(Fertility~., data=swiss)
summary(lm2)#3.5
# use model with all predictors ~.
lm2 <- lm(Fertility~., data=swiss)
summary(lm2)
lm3 <- lm(Fertility~Education+Catholic+Infant.Mortality, data=swiss)
summary(lm3)
#lm2 is best model
anova(lm1,lm2,lm3)
# Linear regression
# show all data sets in R
data()
# learn about swiss
?swiss
#
str(swiss)
#
head(swiss)
attach(swiss)
# build a predicting model
plot(swiss$Fertility~swiss$Education)
lm1 <- lm(Fertility~Education, data=swiss)
summary(lml)
#education had a close P value
# 3.2
cov(swiss$Fertility,swiss$Education)
cor(swiss$Fertility,swiss$Education)
#3.5
# use model with all predictors ~.
lm2 <- lm(Fertility~., data=swiss)
summary(lm2)
lm3 <- lm(Fertility~Education+Catholic+Infant.Mortality, data=swiss)
summary(lm3)
#lm2 is best model
anova(lm1,lm2,lm3)
library(HSAUR)
data(plasma)
str(plasma)
require(HSuar)
require(HSUAR)
library(HSAUR)
library('HSAUR')
df <- read.csv("data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("./data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv(".data/titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("//data//titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
set.seed(1234)
i <- sample(1:nrow(df), 0.75*nrow(df), replace=FALSE)
train <- df[i,]
test <- df[-i,]
df <- read.csv("//data//titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("\\data\\titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
df <- read.csv("C:\\Users\\kim\\Desktop\\Screen-Cleaner\\GitHub\\Learning_from_Data\\Part_2_Linear_Models\\data\\titanic3.csv", header=TRUE)
df <- df[,c(1,2,4,5)]
df$pclass <- factor(df$pclass)
df$survived <- factor(df$survived)
df <- df[!is.na(df$pclass),]
df <- df[!is.na(df$survived),]
df$age[is.na(df$age)] <- median(df$age,na.rm=T)
set.seed(1234)
i <- sample(1:nrow(df), 0.75*nrow(df), replace=FALSE)
train <- df[i,]
test <- df[-i,]
set.seed(1234)
i <- sample(1:nrow(df), 0.75*nrow(df), replace=FALSE)
train <- df[i,]
test <- df[-i,]
library(e1071)
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
install.packages(e1071)
library(e1071)
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
install.packages("e1071")
library(e1071)
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
install.packages("e1071")
library("e1071")
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
install.packages("e1071")
install.packages("e1071")
library("e1071")
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
install.packages("e1071")
install.packages("e1071")
library("e1071")
svm1 <- svm(survived~., data=train, kernel="linear", cost=10, scale=TRUE)
pred <- predict(svm1, newdata=test)
table(pred, test$survived)
mean(pred==test$survived)
set.seed(1958)
i <- sample(150, 100, replace=TRUE)
train <- iris[i,]
test <- iris[-i,]
svm2 <- svm(Species~., data=train, kernel="linear", cost=10, scale=TRUE)
pred <- predict(svm2, newdata=test)
table(pred, test$Species)
mean(pred==test$Species)
svm3 <- svm(Species~., data=train, kernel="linear", cost=10, scale=TRUE)
plot(svm3, iris, Petal.Width ~ Petal.Length,
slice = list(Sepal.Width = 3, Sepal.Length = 4))
pred <- predict(svm3, newdata=test)
table(pred, test$Species)
mean(pred==test$Species)
plot(svm3, test, Petal.Width ~ Petal.Length,
slice = list(Sepal.Width = 3, Sepal.Length = 4))
library(MASS)
df <- Boston[]
str(df)
library(tree)
install.packages('tree')
library(tree)
library(MASS)
names(Boston)
install.packages('tree')
library(tree)
library(MASS)
names(Boston)
install.packages("tree")
#install.packages('tree')
library(tree)
library(MASS)
names(Boston)
set.seed(1234)
i <- sample(nrow(Boston), 0.8*nrow(Boston), replace = FALSE)
train <- Boston[i,]
test <- Boston[-i,]
lm1 <- lm(medv~., data=train)
summary(lm1)
pred <- predict(lm1, newdata=test)
cor(pred, test$medv)
## [1] 0.900081
rmse <- sqrt(mean((pred-test$medv)^2))
Using tree
pred <- predict(lm1, newdata=test)
cor(pred, test$medv)
## [1] 0.900081
rmse <- sqrt(mean((pred-test$medv)^2))
tree1 <- tree(medv~., data=train)
summary(tree1)
pred <- predict(tree1, newdata=test)
cor(pred, test$medv)
## [1] 0.8913526
rmse <- sqrt(mean((pred-test$medv)^2))
plot(tree1)
text(tree1, cex=0.5, pretty=0)
cross validation
pred <- predict(lm1, newdata=test)
cor(pred, test$medv)
## [1] 0.900081
rmse <- sqrt(mean((pred-test$medv)^2))
tree1 <- tree(medv~., data=train)
summary(tree1)
pred <- predict(tree1, newdata=test)
cor(pred, test$medv)
## [1] 0.8913526
rmse <- sqrt(mean((pred-test$medv)^2))
plot(tree1)
text(tree1, cex=0.5, pretty=0)
cv_tree <- cv.tree(tree1)
plot(cv_tree$size, cv_tree$dev, type='b')
prune the tree
pred <- predict(lm1, newdata=test)
cor(pred, test$medv)
## [1] 0.900081
rmse <- sqrt(mean((pred-test$medv)^2))
tree1 <- tree(medv~., data=train)
summary(tree1)
pred <- predict(tree1, newdata=test)
cor(pred, test$medv)
## [1] 0.8913526
rmse <- sqrt(mean((pred-test$medv)^2))
plot(tree1)
text(tree1, cex=0.5, pretty=0)
cv_tree <- cv.tree(tree1)
plot(cv_tree$size, cv_tree$dev, type='b')
tree_pruned <- prune.tree(tree1, best=5)
plot(tree_pruned)
text(tree_pruned, pretty=0)
pred_pruned <- predict(tree_pruned, newdata=test)
cor(pred_pruned, test$medv)
## [1] 0.8456787
rmse <- sqrt(mean((pred_pruned-test$medv)^2))
library(randomForest)
# install and load packages
if(!require('tinytex')){
install.packages('tinytex')
library('tinytex')
}
# different file locations for the project
dataPathHomeComputer <- "C:\\Users\\Alex\\Desktop\\Screen-Cleaner\\GitHub\\UTDSummer2018\\CS-4375.0U2-Machine-Learning\\Projects\\project1\\data\\processed.hungarian.data"
dataPathSchoolComputer <- "H:\\GitHub\\UTDSummer2018\\CS-4375.0U2-Machine-Learning\\Projects\\project1\\data\\processed.hungarian.data"
# create the dataframe for heart disease
df_hd <- read.table(dataPathHomeComputer)
# install and load packages
if(!require('tinytex')){
install.packages('tinytex')
library('tinytex')
}
# different file locations for the project
dataPathHomeComputer <- "C:\\Users\\kim\\Desktop\\Screen-Cleaner\\GitHub\\UTDSummer2018\\CS-4375.0U2-Machine-Learning\\Projects\\project1\\data\\processed.hungarian.data"
dataPathSchoolComputer <- "H:\\GitHub\\UTDSummer2018\\CS-4375.0U2-Machine-Learning\\Projects\\project1\\data\\processed.hungarian.data"
# create the dataframe for heart disease
df_hd <- read.table(dataPathHomeComputer)
# sets the column names of the data frame with colnames function
colnames(df_hd) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")
# separate out the train and test dataframes following a similar naming convention of original frame
# Set random seed to ensure reproducibility of the shuffle.
set.seed(1958)
# shuffle the df_hd and store into a new df_hd frame
df_hd_numberOfRows <- nrow(df_hd)
shuf_df_hd <- df_hd[sample(df_hd_numberOfRows), ]
# set train_data df_hd with the train_data indices
train_data_indices <- 1:round(0.75 * df_hd_numberOfRows)
train_data <- shuf_df_hd[train_data_indices, ]
# set test_data df_hd with the test_data indices
test_data_indices <- (round(0.75 * df_hd_numberOfRows) + 1):df_hd_numberOfRows
test_data <- shuf_df_hd[test_data_indices, ]
# look at the names of the data frame
nameArray <- names(df_hd)
printString <- "The names of the columns are:"
# print a useful message with a compact version of the columns using str
print(printString)
str(nameArray)
# show first 6 instances of the frame
head(df_hd)
# store a summary of the data frame
sm <- summary(df_hd)
# print the summary
print(sm)
# coerce all predictors and targets as numeric for correlation function
xPredictor <- as.numeric(df_hd$cp)
yTarget <- as.numeric(df_hd$num)
print("Correlation of -- Chest pain and heart disease:")
cor(xPredictor, yTarget)
xPredictor <- as.numeric(df_hd$exang)
print("Correlation of -- Exercise induced chest pain and heart disease:")
cor(xPredictor, yTarget)
xPredictor <- as.numeric(df_hd$oldpeak)
print("Correlation of -- ST depression, aka irregular heart beat, due to exercise and heart disease:")
cor(xPredictor, yTarget)
xPredictor <- as.numeric(df_hd$slope)
print("Correlation of -- Slope of ST depression during peak exercise and heart disease:")
cor(xPredictor, yTarget)
# scatterplot for data view
scatter.smooth(x=df_hd$cp, y=df_hd$num, main="Scatterplot Chest Pain ~ Heart Disease", xlab="Chest Pain (types 1 through 4)", ylab="Heart disease (< .5 positive diagnosis)")
# # Density plot
par(mfrow=c(1, 2))  # divide graph area in 2 columns
plot(density(df_hd$cp), main="Density Plot: Chest Pain", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(df_hd$cp), 2)))
polygon(density(df_hd$cp), col="red")
plot(density(df_hd$exang), main="Density Plot: Exercise induced CP", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(df_hd$exang), 2)))
polygon(density(df_hd$exang), col="red")
# create linear model on train_data
train_lm1 <- lm(as.numeric(exang)~as.numeric(num), data=train_data)
print(train_lm1 )
plot(train_lm1)
# store a summary of the model created from the train data and print it
lm1_sm <- summary(train_lm1)
print(lm1_sm)
# attempt to predict the target y value of the test data with the train linear model
pred <- predict(train_lm1, newdata=test_data)
print("Correlation of -- Prediction of heart disease using training model with test data:")
cor(pred, as.numeric(test_data$exang))
# install and load packages
if(!require('caret')){
install.packages('caret')
library('caret')
}
