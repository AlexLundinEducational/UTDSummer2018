---
output:
  word_document: default
  pdf_document: default
  html_document: default
---

Name: Alex Lundin
Assignment: Project 2
# Header for project

Data URL:

https://www.kaggle.com/open-powerlifting/powerlifting-database

Data Overview:

Data Label 			  Data Type 					Data Description
MeetID	          Int
Name	            Factor
Sex	              Factor
Equipment	        Factor
Age	              Double
Division	        Factor
BodyweightKg	    Double
WeightClassKg	    Factor
Squat4Kg	        Double
BestSquatKg	      Double
Bench4Kg	        Double
BestBenchKg	      Double
Deadlift4Kg	      Double
BestDeadliftKg	  Double
TotalKg	          Double
Place	            Factor
Wilks             Double

# Load data												        
```{r}
# store path string for loading csv file
dataPathHomeComputer <- "C:\\Users\\Kim\\Desktop\\data\\openpowerlifting.csv"

df_pl <- read.csv(dataPathHomeComputer)
```


# investigate the data with names, str, head, summary and cor
```{r}
# show how many rows
paste("There are 386414 observances, also known as rows.")
str(df_pl)

# look at the names of the data frame
nameArray <- names(df_pl)

# print a useful message with a compact version of the columns
paste("The names of the columns are:")
paste("Column:", nameArray)

# show first 6 instances of the frame
head(df_pl)

# add a new column called win
df_pl$Win <- ifelse(df_pl$Place == 1, 1, 0)

print("New Column:")

table(df_pl$Win)


```

# Summary
```{r}
# store a summary of the data frame, after addition of new column
sm <- summary(df_pl)

# print the summary
print(sm)
```

# Train and Test	
```{r}

# I have to omit NA's to get ML algorithims to work
df_pl <- na.omit(df_pl)


# Set random seed to ensure reproducibility of the shuffle.
set.seed(1958)

# separate out the train and test dataframes following a similar naming convention of original frame
# I have to Split data exactly in half for some algorithims
# I'm only using a small fraction of the entire data set due to the NA ommisions
train_data = df_pl[1:(0.5*nrow(df_pl)),]
dim(train_data)
test_data = df_pl[((0.5*nrow(df_pl))+1):((0.5*nrow(df_pl)*2)),]
dim(test_data)

```

Show correlations to view data

Bench press is highly correlated with wining the entire competition
.30

```{r}
if(!require("corrplot")){
  install.packages("corrplot")  
  library("corrplot")
}
library(corrplot)
x <- cor((df_pl[,c(5,7,9,10,11,12,13,14,15,18)]))
corrplot(x, type="upper", order="hclust")


```

Feature selection with rcorr matrix

```{r}
if(!require("Hmisc")){
  install.packages("Hmisc")  
  library("Hmisc")
}

correlationMatrix <- rcorr(as.matrix(df_pl[,c(5,7,9,10,11,12,13,14,15,18)]))

# access the correlation efficients only, using $r
# column 10 is how every column correlates with winning the meet
correlationWithWin <- correlationMatrix$r[,c(10)]

# sets the column names of the data frame with colnames function
columnNames <- c("Age", "Weight", "Squat", "B.Squat", "Bench", "B.Bench", "Dead", "B.Dead", "TotalKg", "Win")
correlationCoefficients <- correlationMatrix$r[1,c(10)]

for (i in 1:10) {
  name <- columnNames[i]
  value <- correlationWithWin[i]
  print(paste("Current column is:", name))
  print(paste("Current value is:", value))

}
paste("Vector print loop done.")

correlation_df <- data.frame(columnNames, correlationWithWin)

plot(correlation_df)


```


Logistic regression model
   Target: Win
   Predictor: bench press
   
   Evaluation:
      accuracy =  0.80952380952381
  
      this model achieved the highest accuracy, I think this model did the best because of the size       of the data set.
# first model for power lifting      
```{r}
# logistic regression
glm0 <- glm(train_data$Win~train_data$Bench4Kg, data=train_data, family=binomial)
summary(glm0)

# summarize the model
train_glm_sum <- summary(glm0)

# create prediction off model
probs <- predict(glm0, newdata=test_data)
pred <- ifelse(probs>0.5, 1, 0)

# use accuracy to evaluate
acc <- mean(pred==test_data$Win)
print(paste("accuracy = ", acc))
table(pred, test_data$Win) 

```

Decision Tree Model
   Target: Win
   Predictors: bench press
   
   Evaluation:
      accuracy    =  0.43
      
# second model for powerlifting
```{r}
if(!require('tree')){
  install.packages('tree')  
  library('tree')
}

# create model
tree_1 <- tree(train_data$Win~train_data$Bench4Kg, data=train_data)

# create predictions
pred <- predict(tree_1, newdata=test_data)

# evaluate model
rmse <- sqrt(mean((pred-test_data$Win)^2))
paste("Accuracy is:", rmse)
```



Knn regression model
   Target: Win
   Predictors: bench press and best bench press
   
   Evaluation:
      best k      =  13
      accuracy    =  0.19047619047619
      
# third model for powerlifting
```{r}

if(!require("caret")){
  install.packages("caret")  
  library("caret")
}

if(!require("DMwR")){
  install.packages("DMwR")  
  library("DMwR")
}

fit <- knnreg(train_data[,c(11,12)],train_data[,18],k=3)
predictions <- predict(fit, test_data[,c(11,12)])
cor(predictions, test_data[,18])
mse <- mean((predictions - test_data$Win)^2)
paste("Accuracy is:", mse)

```


# find best k
```{r}
cor_k <- rep(0, 20)
mse_k <- rep(0, 20)
i <- 1
for (k in seq(1, 39, 2)){
  fit_k <- knnreg(train_data[,c(11,12)],train_data[,18],k=k)
  pred_k <- predict(fit_k, test_data[,c(11,12)])
  cor_k[i] <- cor(pred_k, test_data[,18])
  mse_k[i] <- mean((pred_k - test_data[,18])^2)
  print(paste("k=", k, cor_k[i], mse_k[i]))
  i <- i + 1
}

```

# print data for best K
```{r}
fit_13 <- knnreg(train_data[,c(11,12)],train_data[,18],k=13)
predictions <- predict(fit_13, test_data[,c(11,12)])
mse <- mean((predictions - test_data[,18])^2)

paste("Accuracy is:", mse)

```

